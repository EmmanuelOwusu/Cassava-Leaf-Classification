{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretrainedmodels\n",
    "import pretrainedmodels as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# from fastai.vision import *\n",
    "# import fastai\n",
    "# from PIL import Image\n",
    "# import shutil\n",
    "# import fastai\n",
    "# from fastai import vision\n",
    "\n",
    "#!pip install pretrainedmodels\n",
    "#mport pretrainedmodels \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../input/ammi-2020-convnets/train/train\"\n",
    "test_path = \"../input/ammi-2020-convnets/test/test\"\n",
    "extraimage_path = \"../input/ammi-2020-convnets/extraimages/extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_path)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# import cv2\n",
    "# image=cv2.imread('data_path/cmd/train-cmd-1992.jpg')\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for both the training and testing data\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(448),\n",
    "                                       transforms.RandomVerticalFlip(),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(448),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomVerticalFlip(),\n",
    "                                      # transforms.CenterCrop(244),\n",
    "                                       transforms.ToTensor()])\n",
    "# train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "#                                        transforms.RandomResizedCrop(448),\n",
    "#                                        transforms.RandomHorizontalFlip(),\n",
    "#                                        transforms.ToTensor()])\n",
    "\n",
    "# test_transforms = transforms.Compose([ transforms.Resize(255),\n",
    "#                                        transforms.CenterCrop(224),\n",
    "#                                        transforms.ToTensor()])\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.transform = transform\n",
    "\n",
    "        files = []\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "        self.file_list = files\n",
    "        files = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "            \n",
    "        return im.view(3, 448, 448), classCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
    "test_data = CassavaDataset(test_path, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n",
    "                                             sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n",
    "                                             sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Models \n",
    "\n",
    "# model = models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "# for param in model.parameters():\n",
    "#      param.requires_grad = True   \n",
    "    \n",
    "# model.fc = nn.Sequential(\n",
    "#                nn.Linear(2048, 128),# 50176\n",
    "#                nn.ReLU(inplace=True),\n",
    "#                nn.Linear(128, 5)).to(device)\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def se_resnext50_32x4d(pretrained=True):\n",
    "#     pretrained = 'imagenet' if pretrained else None\n",
    "#     model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "#     return model\n",
    "\n",
    "# model = se_resnext50_32x4d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # new final layer with 5 classes\n",
    "# model.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "# num_ftrs = model.last_linear.in_features\n",
    "# model.last_linear = torch.nn.Linear(num_ftrs, 5)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnext101_32x8d(pretrained=True).to(device)\n",
    "# #model = models.squeezenet1_1(pretrained=True).to(device)\n",
    "    \n",
    "# for param in model.parameters():\n",
    "#      param.requires_grad = True   \n",
    "    \n",
    "# model.fc = nn.Sequential(\n",
    "#                nn.Linear(model.fc.in_features, 128),# 50176\n",
    "#                nn.Dropout(0.1),\n",
    "#                nn.ReLU(inplace=True),\n",
    "#                nn.Linear(128, 5)).to(device)\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB, modelC, nb_classes=5):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.modelC = modelC\n",
    "        # Remove last linear layer\n",
    "        self.modelA.fc = nn.Identity()\n",
    "        self.modelB.fc = nn.Identity()\n",
    "        self.modelC.fc = nn.Identity()\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.classifier = nn.Linear(2048+2048+512, nb_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.modelA(x.clone())  # clone to make sure x is not changed by inplace methods\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.modelB(x)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        \n",
    "        x3 = self.modelC(x)\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        x = torch.cat((x1, x2,x3), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x\n",
    "\n",
    "# Train your separate models\n",
    "# ...\n",
    "# We use pretrained torchvision models here\n",
    "modelA = models.resnext101_32x8d(pretrained=True)\n",
    "modelB = model.resnet50(pretrained=True)\n",
    "modelC = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze these models\n",
    "for param in modelA.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "for param in modelB.parameters():\n",
    "    param.requires_grad_(False)\n",
    "    \n",
    "for param in modelC.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "# Create ensemble model\n",
    "model = MyEnsemble(modelA, modelB, modelC).to(device)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def se_resnext101_32x4d(pretrained=True):\n",
    "#     pretrained = 'imagenet' if pretrained else None\n",
    "#     model = pm.se_resnext101_32x4d(pretrained=pretrained)\n",
    "#     return model\n",
    "\n",
    "#     model = se_resnext101_32x4d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.NLLLoss()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "#optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, criterion, data_loader, optimizer,exp_lr_scheduler, num_epochs):\n",
    "#     \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
    "    \n",
    "#     # Make sure model is in training mode.\n",
    "#     model.train()\n",
    "    \n",
    "#     # Move model to the device (CPU or GPU).\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Exponential moving average of the loss.\n",
    "#     ema_loss = None\n",
    "    \n",
    "#     # Loop over epochs.\n",
    "#     for epoch in range(num_epochs):\n",
    "        \n",
    "#       # Loop over data.\n",
    "#       for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            \n",
    "#           # Forward pass.\n",
    "#           output = model(data.to(device))#.to(device)\n",
    "#           loss = criterion(output.to(device), target.to(device))\n",
    "          \n",
    "#           # Backward pass.\n",
    "#           optimizer.zero_grad()\n",
    "#           loss.backward()\n",
    "#           optimizer.step()\n",
    "          \n",
    "#           # NOTE: It is important to call .item() on the loss before summing.\n",
    "#           if ema_loss is None:\n",
    "#             ema_loss = loss.item()\n",
    "#           else:\n",
    "#             ema_loss += (loss.item() - ema_loss) * 0.01 \n",
    "            \n",
    "#       exp_lr_scheduler.step()\n",
    "          \n",
    "#       # Print out progress the end of epoch.\n",
    "#       print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_loss_train, total_acc_train = [],[]\n",
    "# def train( model, criterion,train_loader, optimizer,exp_lr_scheduler, epoch):\n",
    "#     model.train()\n",
    "#     train_loss = AverageMeter()\n",
    "#     train_acc = AverageMeter()\n",
    "#     curr_iter = (epoch - 1) * len(train_loader)\n",
    "#     for i, data in enumerate(train_loader):\n",
    "#         images, labels = data\n",
    "#         N = images.size(0)\n",
    "#         # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "#         images = Variable(images).to(device)\n",
    "#         labels = Variable(labels).to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         prediction = outputs.max(1, keepdim=True)[1]\n",
    "#         train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "#         train_loss.update(loss.item())\n",
    "#         curr_iter += 1\n",
    "#         if (i + 1) % 100 == 0:\n",
    "#             print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "#                 epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "#             total_loss_train.append(train_loss.avg)\n",
    "#             total_acc_train.append(train_acc.avg)\n",
    "#     return train_loss.avg, train_acc.avg\n",
    "\n",
    "\n",
    "\n",
    "total_step = len(train_loader)\n",
    "def train(model, criterion, data_loader, optimizer,scheduler, num_epochs): # scheduler,\n",
    "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
    "    \n",
    "    # Make sure model is in training mode.\n",
    "    model.train()\n",
    "    \n",
    "    # Move model to the device (CPU or GPU).\n",
    "    model.to(device)\n",
    "    \n",
    "    # Exponential moving average of the loss.\n",
    "    ema_loss = None\n",
    "    \n",
    "    # Loop over epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            scheduler.step()\n",
    "        \n",
    "            #if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, data_loader):\n",
    "#     \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
    "#     # Make sure the model is in evaluation mode.\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "\n",
    "#     # We do not need to maintain intermediate activations while testing.\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         # Loop over test data.\n",
    "#         for data, target in data_loader:\n",
    "          \n",
    "#             # Forward pass.\n",
    "#             output = model(data.to(device))\n",
    "            \n",
    "#             # Get the label corresponding to the highest predicted probability.\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "#             # Count number of correct predictions.\\\n",
    "#             correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     # Print test accuracy.\n",
    "#     percent = 100. * correct / int(len(train_data)*validation_split)#len(data_loader.dataset)\n",
    "#     #print(f'Accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n",
    "#     print(f'Accuracy: {correct} / {int(len(train_data)*validation_split)} ({percent:.0f}%)')\n",
    "#     torch.save(model.state_dict(), 'model.ckpt')\n",
    "#     return percent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, num_epochs):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (num_epochs, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " train(model, criterion, train_loader, optimizer,exp_lr_scheduler, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validate(valid_loader, model, criterion, optimizer, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "# num_ftrs = model.last_linear.in_features\n",
    "# model.last_linear = torch.nn.Linear(num_ftrs, 5)\n",
    "# if torch.cuda.is_available():\n",
    "# model = model.cuda()# train(model, criterion, train_loader, optimizer,exp_lr_scheduler, num_epochs=25)\n",
    "# # test(model, valid_loader)#test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved model to make predictions on test data\n",
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = range(1, len(total_acc_train) + 1)\n",
    "# #Train and validation accuracy\n",
    "# plt.plot(epochs, total_acc_train, 'b', label='Train accurarcy')\n",
    "# #plt.plot(epochs, test_accuracy_list, 'r', label='Validation accurarcy')\n",
    "# plt.title('Training and Validation accurarcy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "# #Train and validation loss\n",
    "# plt.plot(epochs, total_loss_train 'b', label='Training loss')\n",
    "# #plt.plot(epochs, validation_loss_list, 'r', label='Validation loss')\n",
    "# plt.title('Training and Validation loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_dir):\n",
    "# Process a PIL image for use in a PyTorch model\n",
    "# tensor.numpy().transpose(1, 2, 0)\n",
    "    image = Image.open(image_dir)\n",
    "    preprocess = transforms.Compose([ transforms.Resize(255),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor()])\n",
    "    image = preprocess(image)\n",
    "  # Convert 2D image to 1D vector\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = torch.from_numpy(image)\n",
    "    inputs = image.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our model to predict the label\n",
    "def predict(image, model):\n",
    "# Pass the image through our model\n",
    "    output = model(image)\n",
    "# Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "# Get the top predicted class, and the output percentage for\n",
    "# that class\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = '../input/ammi-2020-convnets/test/test/0'\n",
    "\n",
    "predictions, test_image_fileName = [], []\n",
    "try:\n",
    "    test_images = listdir(test_directory)\n",
    "    for images in test_images:\n",
    "        test_image_fileName.append(images)\n",
    "        image = process_image(f'{test_directory}/{images}')\n",
    "        top_prob, top_class = predict(image, model)\n",
    "        predictions.append(class_names[top_class])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
